\section{Related Work}
\label{sec:relatedwork}

Embedded platforms are increasingly deployed in environments where adversaries can obtain physical access, interact with programming and debug interfaces, and attempt firmware replacement. Prior work addresses these threats along several directions: (i) BootROM-centered secure boot, (ii) securing longer boot chains (e.g., OS/FPGA-style stacks), (iii) debug and test interface security, (iv) hardware-enforced trusted execution and minimal TCB designs, (v) software-only hardening, and (vi) compiler, toolchain, and binary-translation infrastructures that make low-level enforcement mechanisms practical to deploy. This section reviews these approaches and motivates instruction-triggered, key-gated authorization with toolchain support.

\subsection{BootROM-Based Secure Boot and Early-Stage Integrity}
Secure boot typically anchors trust in immutable first-stage code (BootROM/ROM-resident loader) that authenticates subsequent software before execution. Bin \emph{et al.} design BootROM support for secure boot mode, reinforcing the BootROM’s role as the earliest enforcement point and focusing on validating system images during startup to prevent unauthorized firmware execution~\cite{bin2020bootrom}. Complementing this, Rashmi R.\,V. and Karthikeyan survey secure boot techniques for embedded applications, highlighting common architectural patterns and practical constraints (e.g., resource limits, deployment workflow) that shape how image authentication is implemented~\cite{rv2018securebootreview}. While these works establish boot-time authenticity as a baseline, they leave open how \emph{post-boot} privileged actions (e.g., enabling debug/program access) should be authorized once some code is running—particularly under physical-access threat models where adversaries can iteratively probe and reflash.

A related line of work emphasizes extending boot trust into device identity and measurement chains. J{\"a}ger and Petri present a hardware implementation of the Device Identifier Composition Engine (DICE), illustrating how device identity composition can be realized as a concrete hardware mechanism for bootstrapping device trust~\cite{jaeger2020diceharder}. Broader surveys of secure boot schemes discuss design trade-offs across embedded platforms and deployment models~\cite{wang2022securebootsurvey}. Boot-time trust can also be coupled with measured-boot style techniques that establish trust properties over commodity systems and their boot stacks~\cite{parno2010bootstrapping}.

\subsection{Boot-Chain Protection for Richer Stacks (Embedded Linux / FPGA Systems)}
As embedded systems incorporate more complex boot sequences (multiple software stages, configuration artifacts, and OS components), integrity must extend beyond a single image check. Devic \emph{et al.} explicitly address this problem for an embedded Linux boot flow on FPGA, securing the boot process against tampering and replay attacks by verifying artifacts in a multi-stage chain~\cite{devic2011fpga}. This class of work motivates defenses that remain robust when attackers target whichever stage is easiest to manipulate.

\subsection{Debug/Test/Programming Interface Security}
Debug and test access are widely recognized as high-impact attack surfaces because they provide invasive control over execution, memory, and device state. IEEE~1149.1 standardizes the test access port and boundary-scan architecture that underpins much of the modern debug/test ecosystem~\cite{ieee1149_1}. Beyond standardization, boundary-scan/test-mode pathways can enable attacks when an adversary can enter privileged test states~\cite{ali2014boundaryscanattack}. Recent work also explores adding explicit authentication mechanisms to debug access; for example, Lapeyre \emph{et al.} propose a lightweight JTAG authentication IP intended to support secure device testing while restricting unauthorized debug usage~\cite{lapeyre2022jtagauth}.

Additional work examines authenticated or enhanced debug access mechanisms and the practical debug infrastructure surrounding JTAG. Schnorr-based identity authentication has been explored for secure JTAG debugging models~\cite{wang2020schnorrjtag}, while other efforts extend JTAG for at-speed debug or provide JTAG-based debug IP implementations and emulation tools~\cite{vandelogt2003jtag,walimbe2014jtagaxi,chen2008jtagemu}. Together, these works motivate treating debug enablement as a privileged capability and binding it to explicit authorization.

\subsection{Hardware-Enforced Trusted Execution and Minimal-TCB Approaches}
TrustZone-style partitioning provides a widely deployed model for separating a trusted execution domain from the normal execution environment. Security evaluations of TrustZone in heterogeneous SoCs highlight practical considerations and attack surfaces when the extension is integrated into real systems~\cite{zhang2017trustzoneeval}. Open-platform efforts such as Keystone demonstrate how trusted execution environments (TEEs) can be engineered with explicit, auditable interfaces~\cite{lee2020keystone}. In parallel, systems such as TrustVisor, Flicker, and Memoir motivate minimizing trusted code while maintaining measured execution and continuity guarantees~\cite{mccune2010trustvisor,mccune2008flicker,parno2011memoir}. For embedded-scale devices, TrustLite proposes isolation mechanisms tailored to constrained systems~\cite{koeberl2014trustlite}.

Secure-processor and minimal-context execution designs provide additional perspective on enforcing security properties below untrusted software. AEGIS proposes a single-chip secure processor model~\cite{suh2005aegis}, and minimal TCB code-execution frameworks explore reducing trusted code footprint for sensitive operations~\cite{mccune2007minimaltcb}. Complementary survey and analysis work on TEEs and secure processors provides additional context on enclave-style designs and their assumptions~\cite{costan2017secureprocessors,ahmed2025riscvtee}. Roots-of-trust work further motivates establishing trust from small, well-defined code bases; for example, software-root-of-trust designs address trust establishment without relying on large trusted stacks~\cite{gligor2019establishing}.

\subsection{Runtime Integrity and Attestation for Embedded Systems}
Beyond boot-time authenticity, several approaches aim to provide evidence of runtime integrity and control-flow correctness. Remote attestation mechanisms for embedded systems have been studied in various forms~\cite{kylanpaa2016remoteattest}, and cumulative attestation kernels extend attestation by accumulating evidence across execution~\cite{lemay2012cumulative}. Collective attestation considers stronger security properties in embedded networks by coordinating attestation across devices~\cite{ibrahim2018collectiveatt}.

More recently, control-flow attestation has been explored as a lightweight alternative to full-blown runtime monitoring. C-FLAT attests control-flow by instrumenting software and producing attestation reports~\cite{abera2016cflat}, while LO-FAT demonstrates a low-overhead, hardware-assisted direction for control-flow attestation~\cite{dessouky2017lofat}. Additional directions include log-based and micro-architectural (e.g., nanovised) control-flow attestation methods~\cite{liu2019logbasedcfa,benyehuda2022nanovised}. These lines of work are complementary to key-gated authorization: rather than preventing unauthorized programming/debug directly, they provide evidence about executed control flow and runtime state.

\subsection{System Assurance via Formal Verification}
Because low-level enforcement mechanisms are security-critical, prior work emphasizes formal verification as a path to high assurance. The seL4 microkernel demonstrates formal verification at the operating-system kernel level~\cite{klein2009sel4,klein2014tocs}.

\subsection{Software-Only Hardening: Obfuscation and Key-Dependent Checks}
Software protection techniques deter tampering and reverse engineering by transforming code or embedding secret-dependent checks. Recent taxonomies provide structured views of layered obfuscation techniques and their security goals in modern software protection pipelines~\cite{tran2020layered}.

Related work in software-only enforcement also includes control-flow protection and exploitation models. Control-Flow Integrity (CFI) constrains indirect control transfers to a precomputed graph, aiming to limit control-flow hijacking~\cite{abadi2005cfi}. Conversely, return-oriented programming (ROP) demonstrates how attackers can construct malicious computation from existing code snippets without injecting new code, motivating defenses that restrict or authenticate sensitive execution paths~\cite{checkoway2010rop}. While these are not direct substitutes for device-bound authorization, they contextualize the broader threat landscape for embedded software integrity.

\subsection{Toolchain Infrastructure, ISA Extensibility, and Deployable Low-Level Mechanisms}
Many enforcement mechanisms require reliable support from the compiler and binary utilities. Shen \emph{et al.} present LLBT, an LLVM-based static binary translator~\cite{shen2012llbt}. Zakai introduces Emscripten, an LLVM-to-JavaScript compiler~\cite{zakai2011emscripten}. Finally, RISC-V’s explicit support for extensibility motivates instruction-level mechanisms that remain compatible with conventional toolchains and disassembly workflows~\cite{waterman2014riscv}.

LLVM itself is widely used as a substrate for program analysis and transformation, enabling compiler-integrated instrumentation and retargeting workflows that are relevant when introducing new ISA-level primitives~\cite{lattner2004llvm}. This motivates implementing custom authorization instructions and associated metadata through toolchain support rather than ad-hoc binary rewriting.

